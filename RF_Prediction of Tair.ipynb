{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sally-Ama-Sampson/Estimating-Tair-from-CS-generated-Data-/blob/main/RF_Prediction%20of%20Tair.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c717bff-2bce-48bc-ab48-bf1a0c15aa2e",
      "metadata": {
        "id": "2c717bff-2bce-48bc-ab48-bf1a0c15aa2e"
      },
      "outputs": [],
      "source": [
        "import geopandas as gpd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "import sklearn.ensemble\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import math\n",
        "from tqdm import tqdm\n",
        "import zipfile"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ALL_DATA = '/content/drive/My Drive/PHD/Onekana/Modelling/Objective 3(Modelling)/50m_grids.gpkg'"
      ],
      "metadata": {
        "id": "bXXfsp5eHgEg"
      },
      "id": "bXXfsp5eHgEg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "V4MlKUdSsxZl",
      "metadata": {
        "id": "V4MlKUdSsxZl"
      },
      "outputs": [],
      "source": [
        "## Adjusting for elevation influence\n",
        "ALL_DATA['Temp_Elevation'] = ALL_DATA['temp_adjust'] + ((6.5 / 1000) * (ALL_DATA['Elevation'] - 1683))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature Selection and Engineering\n",
        "\n",
        "Feature Selection based on Correlation Analysis:\n",
        "\n",
        "This process identifies strongly correlated feature pairs (|correlation| > 0.80) to detect multicollinearity and redundancy among predictors.\n",
        "Features that appear frequently in these high-correlation pairs are selected as key representatives of correlated groups.\n",
        "Additionally, important domain-specific columns are retained regardless of correlation.\n",
        "The goal is to simplify the dataset by reducing redundant features, improving model stability, interpretability, and computational efficiency.\n",
        "\n",
        "\n",
        "\n",
        "Feature Engineering using Log Transformation:\n",
        "\n",
        "Reduce skewness in features by applying a log transformatio: log1p (log(1 + x))\n",
        "This helps make data distributions more balanced, improving model performance and stability.\n",
        "Key columns are excluded from transformation to preserve their original meaning."
      ],
      "metadata": {
        "id": "Sj1VkZ1gKPmH"
      },
      "id": "Sj1VkZ1gKPmH"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "PqmIkQwtnVyh",
      "metadata": {
        "id": "PqmIkQwtnVyh"
      },
      "outputs": [],
      "source": [
        "X_features = ALL_DATA.drop(columns=['temp_adjust','temp_crt', 'geometry'])\n",
        "corr_matrix = X_features.corr()\n",
        "mask = np.abs(corr_matrix) < 0.80\n",
        "filtered_corr = corr_matrix.copy()\n",
        "filtered_corr[mask] = np.nan\n",
        "plt.figure(figsize=(16, 12))\n",
        "sns.set(font_scale=1)\n",
        "\n",
        "ax = sns.heatmap(\n",
        "    filtered_corr,\n",
        "    annot=True,\n",
        "    fmt=\".2f\",\n",
        "    cmap=\"coolwarm\",\n",
        "    linewidths=0.5,\n",
        "    linecolor='gray',\n",
        "    vmin=-1, vmax=1\n",
        ")\n",
        "plt.title(\"Correlation Heatmap (|r| > 0.80)\", fontsize=16)\n",
        "plt.xticks(rotation=90)\n",
        "plt.yticks(rotation=0)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "j-wdBbE6eR3x",
      "metadata": {
        "id": "j-wdBbE6eR3x"
      },
      "outputs": [],
      "source": [
        "high_corr_pairs = (\n",
        "    corr_matrix.where(np.abs(corr_matrix) > 0.80)\n",
        "    .stack()\n",
        "    .reset_index()\n",
        ")\n",
        "high_corr_pairs.columns = ['Feature_1', 'Feature_2', 'Correlation']\n",
        "high_corr_pairs = high_corr_pairs[high_corr_pairs['Feature_1'] != high_corr_pairs['Feature_2']]\n",
        "high_corr_pairs = high_corr_pairs.drop_duplicates(subset=['Correlation'])\n",
        "high_corr_pairs = high_corr_pairs.sort_values(by='Correlation', ascending=False)\n",
        "print(high_corr_pairs.head(20))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "t1wX1OVvxT0t",
      "metadata": {
        "id": "t1wX1OVvxT0t"
      },
      "outputs": [],
      "source": [
        "threshold = 4\n",
        "feature_counts = pd.concat([high_corr_pairs[\"Feature_1\"], high_corr_pairs[\"Feature_2\"]]).value_counts()\n",
        "selected_features = feature_counts[feature_counts > threshold].index.tolist()\n",
        "unselected_features = feature_counts[feature_counts <= threshold].index.tolist()\n",
        "print(f\"{len(unselected_features)} unselected_features\")\n",
        "print(unselected_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "PXcnNVRMVqKE",
      "metadata": {
        "id": "PXcnNVRMVqKE"
      },
      "outputs": [],
      "source": [
        "columns_to_keep = ['NDVI','NDWI', 'NDBI','LST_Night','LST_DAY','Elevation', 'geometry', 'bOrient_me','temp_adjust']\n",
        "selected_features = list(selected_features)\n",
        "final_columns = list(set(columns_to_keep + selected_features))\n",
        "ALL_DATA = ALL_DATA[final_columns]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "jTIHUqm3W-Kz",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "jTIHUqm3W-Kz",
        "outputId": "4f536120-312b-462f-f61c-9380b49a132b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Join_Cou_1',\n",
              " 'LST_Night',\n",
              " 'LST_DAY',\n",
              " 'Elevation',\n",
              " 'NDVI',\n",
              " 'uID',\n",
              " 'tArea',\n",
              " 'tCirCom',\n",
              " 'tERI',\n",
              " 'tcOrient',\n",
              " 'tARatio',\n",
              " 'tWNeigh',\n",
              " 'tFArRatio',\n",
              " 'Height',\n",
              " 'bArea',\n",
              " 'bCirCom',\n",
              " 'bCorner',\n",
              " 'bSquare',\n",
              " 'bERI',\n",
              " 'bFormFact',\n",
              " 'bCCD',\n",
              " 'bShdwall',\n",
              " 'bCellAll',\n",
              " 'bAli',\n",
              " 'bNeiDis',\n",
              " 'bAdj',\n",
              " 'bMIBD',\n",
              " 'tCirCom_me',\n",
              " 'tERI_meanI',\n",
              " 'tCArea_mea',\n",
              " 'bArea_mean',\n",
              " 'bVol_meanI',\n",
              " 'bCirCom_me',\n",
              " 'bCorner_me',\n",
              " 'bSquare_me',\n",
              " 'bFormFact_',\n",
              " 'bOrient_me',\n",
              " 'bShdwall_m',\n",
              " 'bCellAll_m',\n",
              " 'bAli_meanI',\n",
              " 'tCirCom_ra',\n",
              " 'tERI_range',\n",
              " 'tcOrient_r',\n",
              " 'tARatio_ra',\n",
              " 'tWNeigh_ra',\n",
              " 'tFArRati_1',\n",
              " 'Height_ran',\n",
              " 'bArea_rang',\n",
              " 'bCirCom_ra',\n",
              " 'bElong_ran',\n",
              " 'bFormFac_1',\n",
              " 'bOrient_ra',\n",
              " 'bAli_range',\n",
              " 'bAdj_range',\n",
              " 'bMIBD_rang',\n",
              " 'tArea_thei',\n",
              " 'tcOrient_t',\n",
              " 'tCArea_the',\n",
              " 'tFArRati_2',\n",
              " 'Height_the',\n",
              " 'bArea_thei',\n",
              " 'bCorner_th',\n",
              " 'bSquare_th',\n",
              " 'bCCD_theil',\n",
              " 'bOrient_th',\n",
              " 'bCellAll_t',\n",
              " 'bAli_theil',\n",
              " 'bNeiDis_th',\n",
              " 'bMIBD_thei',\n",
              " 'temp_crt',\n",
              " 'NDBI',\n",
              " 'NDWI',\n",
              " 'Shape_Leng',\n",
              " 'temp_adjust',\n",
              " 'is_valid',\n",
              " 'geometry']"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ALL_DATA.columns.to_list()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "w5GoxHSDWrTm",
      "metadata": {
        "collapsed": true,
        "id": "w5GoxHSDWrTm"
      },
      "outputs": [],
      "source": [
        "\n",
        "X_features = ALL_DATA_newtemp.drop(columns=['temp_adjust','geometry'])\n",
        "corr_matrix = X_features.corr()\n",
        "mask = np.abs(corr_matrix) < 0.80\n",
        "filtered_corr = corr_matrix.copy()\n",
        "filtered_corr[mask] = np.nan\n",
        "\n",
        "plt.figure(figsize=(16, 12))\n",
        "sns.set(font_scale=1)\n",
        "\n",
        "ax = sns.heatmap(\n",
        "    filtered_corr,\n",
        "    annot=True,\n",
        "    fmt=\".2f\",\n",
        "    cmap=\"coolwarm\",\n",
        "    linewidths=0.5,\n",
        "    linecolor='gray',\n",
        "    vmin=-1, vmax=1\n",
        ")\n",
        "\n",
        "plt.title(\"Correlation Heatmap (|r| > 0.80)\", fontsize=16)\n",
        "plt.xticks(rotation=90)\n",
        "plt.yticks(rotation=0)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "QBEm5OghlSH8",
      "metadata": {
        "collapsed": true,
        "id": "QBEm5OghlSH8"
      },
      "outputs": [],
      "source": [
        "skewness = ALL_DATA.skew().sort_values(ascending=False)\n",
        "print(\"Top 10 Most Skewed Features:\")\n",
        "print(skewness.head(40))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dpHPwlefl718",
      "metadata": {
        "id": "dpHPwlefl718",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "skewed_features = skewness[abs(skewness) > 1].index[:40]\n",
        "plt.figure(figsize=(25, 25))\n",
        "for i, col in enumerate(skewed_features):\n",
        "    plt.subplot(10, 4, i+1)\n",
        "    sns.histplot(Train_datafiltered[col], kde=True)\n",
        "    plt.title(f\"Skewness of {col}: {skewness[col]:.2f}\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dLmdXnsBJkdT",
      "metadata": {
        "id": "dLmdXnsBJkdT"
      },
      "outputs": [],
      "source": [
        "ALL_DATA_log = ALL_DATA.copy()\n",
        "exclude_cols = ['temp_adjust','temp_crt' ,'geometry', 'Temp_Elevation']\n",
        "numeric_cols = [col for col in ALL_DATA_log.columns if col not in exclude_cols and np.issubdtype(ALL_DATA_log[col].dtype, np.number)]\n",
        "ALL_DATA_log[numeric_cols] = np.log1p(ALL_DATA_log[numeric_cols])\n",
        "new_skewness = ALL_DATA_log[numeric_cols].skew().sort_values(ascending=False)\n",
        "print(\"\\nüìâ Skewness after Log Transformation:\")\n",
        "print(new_skewness.head(10))\n",
        "print(\"\\nüõ†Ô∏è Columns in ALL_DATA_log:\", ALL_DATA_log.columns.tolist())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "K8rACnSMp_fd",
      "metadata": {
        "id": "K8rACnSMp_fd"
      },
      "outputs": [],
      "source": [
        "skewed_features = Train_datafiltered.skew().sort_values(ascending=False).index[:40]\n",
        "\n",
        "plt.figure(figsize=(25, 25))\n",
        "for i, col in enumerate(skewed_features):\n",
        "\n",
        "    plt.subplot(10, 4, i+1)\n",
        "    sns.histplot(ALL_DATA_log[col], kde=True)\n",
        "    plt.title(f\"After Log: {col}\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "h9wgDGm5X-Nx",
      "metadata": {
        "id": "h9wgDGm5X-Nx"
      },
      "source": [
        "## Exploring Different Splitting (Train, Test) Strategies"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### STRATIFIED RANDOM SPLITS"
      ],
      "metadata": {
        "id": "Ca8lMoO7HCnf"
      },
      "id": "Ca8lMoO7HCnf"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ijbJ9aoQnEQy",
      "metadata": {
        "id": "ijbJ9aoQnEQy"
      },
      "outputs": [],
      "source": [
        "gdf = ALL_DATA_log.copy()\n",
        "minx, miny, maxx, maxy = gdf.total_bounds\n",
        "rows, cols = 2, 5\n",
        "grid_width = (maxx - minx) / cols\n",
        "grid_height = (maxy - miny) / rows\n",
        "\n",
        "grids = []\n",
        "for i in range(cols):\n",
        "    for j in range(rows):\n",
        "        grid = box(\n",
        "            minx + i * grid_width,\n",
        "            miny + j * grid_height,\n",
        "            minx + (i + 1) * grid_width,\n",
        "            miny + (j + 1) * grid_height\n",
        "        )\n",
        "        grids.append(grid)\n",
        "\n",
        "grid_gdf = gpd.GeoDataFrame(geometry=grids, crs=gdf.crs)\n",
        "gdf['grid_id'] = gdf.geometry.apply(\n",
        "    lambda point: next((idx for idx, grid in enumerate(grids) if grid.contains(point)), None)\n",
        ")\n",
        "train_list = []\n",
        "test_list = []\n",
        "\n",
        "for grid_id in gdf['grid_id'].unique():\n",
        "    subset = gdf[gdf['grid_id'] == grid_id]\n",
        "    shuffled_indices = subset.sample(frac=1, random_state=229).index\n",
        "    train_size = int(0.8 * len(shuffled_indices))\n",
        "    train_indices = shuffled_indices[:train_size]\n",
        "    test_indices = shuffled_indices[train_size:]\n",
        "    train_list.append(gdf.loc[train_indices])\n",
        "    test_list.append(gdf.loc[test_indices])\n",
        "train_gdf = gpd.GeoDataFrame(pd.concat(train_list).sample(frac=1, random_state=229), crs=gdf.crs).reset_index(drop=True)\n",
        "test_gdf = gpd.GeoDataFrame(pd.concat(test_list).sample(frac=1, random_state=229), crs=gdf.crs).reset_index(drop=True)\n",
        "print(f\"Training Data: {len(train_gdf)} points\")\n",
        "print(f\"Testing Data: {len(test_gdf)} points\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####SPLITTING TRAINING AND VALIDATION SETS SPATIAL DISJOINT\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "bK1ZSVj3GhXA"
      },
      "id": "bK1ZSVj3GhXA"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3975903-b973-4ff5-96e7-e06b388b38db",
      "metadata": {
        "id": "f3975903-b973-4ff5-96e7-e06b388b38db"
      },
      "outputs": [],
      "source": [
        "grid_crs = ALL_DATA_log.crs\n",
        "minx, miny, maxx, maxy = ALL_DATA_log.total_bounds\n",
        "n_divisions = 20\n",
        "x_divisions = np.linspace(minx, maxx, n_divisions + 1)\n",
        "y_divisions = np.linspace(miny, maxy, n_divisions + 1)\n",
        "grid_cells = []\n",
        "for i in range(len(x_divisions) - 1):\n",
        "    for j in range(len(y_divisions) - 1):\n",
        "        grid_cells.append(\n",
        "            shapely.geometry.box(x_divisions[i], y_divisions[j], x_divisions[i + 1], y_divisions[j + 1])\n",
        "        )\n",
        "grid = gpd.GeoDataFrame(grid_cells, columns=['geometry'], crs=grid_crs)\n",
        "Train_data_with_grid_id = gpd.sjoin(ALL_DATA_log, grid, how='left', predicate='within')\n",
        "Train_data_with_grid_id = Train_data_with_grid_id.dropna(subset=['index_right'])\n",
        "intersecting_grid_ids = Train_data_with_grid_id['index_right'].unique()\n",
        "filtered_grid = grid.loc[intersecting_grid_ids]\n",
        "ALL_DATA_log['grid_id'] = Train_data_with_grid_id['index_right']\n",
        "intersection_counts = filtered_grid.apply(lambda x: filtered_grid.intersects(x.geometry).sum(), axis=1)\n",
        "selected_grid_ids = intersection_counts[intersection_counts <= 5].index\n",
        "selected_grid = filtered_grid.loc[selected_grid_ids]\n",
        "\n",
        "selected_points = gpd.sjoin(ALL_DATA_log, selected_grid, how='inner', predicate='within')\n",
        "selected_points = selected_points.drop(columns=['index_right'])\n",
        "selected_points_gdf = gpd.GeoDataFrame(selected_points, crs=ALL_DATA_log.crs)\n",
        "test_gdf = selected_points_gdf\n",
        "\n",
        "sampled_uids = test_gdf['uID']\n",
        "train_gdf = ALL_DATA_log.loc[~ALL_DATA_log.index.isin(sampled_uids)]\n",
        "\n",
        "fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
        "test_gdf.plot(ax=ax, color='green', edgecolors='None', label='VALIDATION')\n",
        "train_gdf.plot(ax=ax, color='red',edgecolors= 'None' ,label='TRAINTEST')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####RANDOMISED SPLITTING"
      ],
      "metadata": {
        "id": "7X15RYVpHa_D"
      },
      "id": "7X15RYVpHa_D"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sQ6mHOsT6lJ4",
      "metadata": {
        "id": "sQ6mHOsT6lJ4"
      },
      "outputs": [],
      "source": [
        "train_gdf, test_gdf = train_test_split(ALL_DATA_log, test_size=0.2, random_state=200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-8ZXBnd54ng4",
      "metadata": {
        "id": "-8ZXBnd54ng4"
      },
      "outputs": [],
      "source": [
        "train_gdf.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5SpGDgm4tCM",
      "metadata": {
        "id": "a5SpGDgm4tCM"
      },
      "outputs": [],
      "source": [
        "test_gdf.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "amC-qV-_7xvV",
      "metadata": {
        "id": "amC-qV-_7xvV"
      },
      "outputs": [],
      "source": [
        "X_train_gdf = train_gdf.drop(['temp_adjust','temp_crt','Elevation','geometry','Temp_Elevation', 'ISI_rf_pred', 'Temp_Elevation1','pointid','LST_20210228_12h44','LST_20210312_19h41', 'NDWI'], axis=1)\n",
        "y_train_gdf = train_gdf['Temp_Elevation']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "TRC8mAKT7_43",
      "metadata": {
        "id": "TRC8mAKT7_43"
      },
      "outputs": [],
      "source": [
        "X_test_gdf = test_gdf.drop(['temp_adjust','temp_crt','geometry','Elevation','Temp_Elevation', 'ISI_rf_pred', 'Temp_Elevation1','pointid','LST_20210228_12h44','LST_20210312_19h41','NDWI'], axis=1)\n",
        "y_test_gdf = test_gdf['Temp_Elevation']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2kr8Xklcnq8D",
      "metadata": {
        "id": "2kr8Xklcnq8D"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_train_gdf_scaled = scaler.fit_transform(X_train_gdf)\n",
        "X_test_gdf_scaled = scaler.fit_transform(X_test_gdf)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bDXcuZgXXjVd",
      "metadata": {
        "id": "bDXcuZgXXjVd"
      },
      "source": [
        "## RF Hyperparameter Tuning and Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "UDfOKchtRsmz",
      "metadata": {
        "id": "UDfOKchtRsmz"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "\n",
        "rf = RandomForestRegressor(oob_score=True, random_state=229)\n",
        "param_dist = {\n",
        "    \"n_estimators\": [200, 500, 800, 1000],\n",
        "    \"max_depth\": [20, 30, 40, None],\n",
        "    \"max_features\": [\"sqrt\", \"log2\", 0.5, 0.7, None],\n",
        "    \"min_samples_split\": [5, 10, 20, 30],\n",
        "    \"min_samples_leaf\": [1, 4, 10, 20],\n",
        "    \"bootstrap\": [True],\n",
        "}\n",
        "\n",
        "n_iter_search = 50\n",
        "random_search = RandomizedSearchCV(\n",
        "        estimator=rf,\n",
        "        param_distributions=param_dist,\n",
        "        n_iter=n_iter_search,\n",
        "        cv=5,\n",
        "        scoring=\"neg_mean_absolute_error\",\n",
        "        n_jobs=-1,\n",
        "        verbose=0,\n",
        "        random_state=42,\n",
        "    )\n",
        "\n",
        "random_search.fit(X_train_gdf, y_train_gdf)\n",
        "best_params = random_search.best_params_\n",
        "\n",
        "best_rf = RandomForestRegressor(**best_params, oob_score=True, random_state=12)\n",
        "best_rf.fit(X_train_gdf, y_train_gdf)\n",
        "\n",
        "print(f\"\\nBest Hyperparameters: {best_params}\")\n",
        "print(f\"Best Cross-Validation MAE: {best_score:.4f}\")\n",
        "print(f\"OOB Score: {best_rf.oob_score_:.4f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "uBCbLAAGRsm0",
      "metadata": {
        "id": "uBCbLAAGRsm0",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_absolute_error, r2_score\n",
        "\n",
        "best_mae = abs(random_search.best_score_)\n",
        "\n",
        "y_pred_train = best_rf.predict(X_train_gdf)\n",
        "\n",
        "best_r2 = r2_score(y_train_gdf, y_pred_train)\n",
        "final_mae = mean_absolute_error(y_train_gdf, y_pred_train)\n",
        "\n",
        "print(f\"\\nBest Hyperparameters: {best_params}\")\n",
        "print(f\"Best Cross-Validation MAE: {best_mae:.4f}\")\n",
        "print(f\"OOB Score: {best_rf.oob_score_:.4f}\")\n",
        "print(f\"Best R¬≤ Score on Training Data: {best_r2:.4f}\")\n",
        "print(f\"Final MAE on Training Data: {final_mae:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "rZi6EzyxP5Yl",
      "metadata": {
        "id": "rZi6EzyxP5Yl"
      },
      "outputs": [],
      "source": [
        "RF_1 =  RandomForestRegressor(oob_score=True, n_estimators = 800, min_samples_split = 8, min_samples_leaf= 8, max_features = 0.7, max_depth = 25, criterion = \"absolute_error\", bootstrap = True,\n",
        "                             random_state=129, n_jobs=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "iYElePYWzONT",
      "metadata": {
        "id": "iYElePYWzONT"
      },
      "outputs": [],
      "source": [
        "RF_1.fit(X_train_gdf, y_train_gdf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2Fg-7IqZGk6h",
      "metadata": {
        "collapsed": true,
        "id": "2Fg-7IqZGk6h"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "with open(file_path, 'wb') as file:\n",
        "    pickle.dump(RF_1, file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "xTChwiqp8mBf",
      "metadata": {
        "id": "xTChwiqp8mBf"
      },
      "outputs": [],
      "source": [
        "training_R2 = r2_score(y_train_gdf, y_train_pred)\n",
        "print(f\"training_R2: {training_R2}\")\n",
        "rmseTrain = math.sqrt(mean_squared_error(y_train_gdf, y_train_pred))\n",
        "print(f\"training_RMSE: {rmseTrain}\")\n",
        "oob_error_rate = RF_FINALBOSS4_scale.oob_score_\n",
        "print(f\"oob_error_rate: {oob_error_rate}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "PAKXIn7P3Q0q",
      "metadata": {
        "id": "PAKXIn7P3Q0q"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_absolute_error\n",
        "y_train_pred = RF_1.predict(X_train_gdf_scaled)\n",
        "training_mae = mean_absolute_error(y_train_gdf, y_train_pred)\n",
        "print(f\"Training Mean Absolute Error: {training_mae}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_gbme11X8xp2",
      "metadata": {
        "id": "_gbme11X8xp2"
      },
      "outputs": [],
      "source": [
        "VALFIN = RF_1.predict(X_test_gdf_scaled)\n",
        "VALFIN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1mApLS-e_aN3",
      "metadata": {
        "id": "1mApLS-e_aN3"
      },
      "outputs": [],
      "source": [
        "Testing_accuracy = RF_1.score(X_test_gdf_scaled, y_test_gdf)\n",
        "print(f'Testing_accuracy: {Testing_accuracy}')\n",
        "r2VAL = r2_score(y_test_gdf, VALFIN)\n",
        "print(f'Testing R-squared (R¬≤) Score: {r2VAL}')\n",
        "rmseVAL = math.sqrt(mean_squared_error(y_test_gdf, VALFIN))\n",
        "print(f'Testing Regression RMSE: {rmseVAL}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "FjbGtM4CGd3V",
      "metadata": {
        "id": "FjbGtM4CGd3V"
      },
      "outputs": [],
      "source": [
        "testing_mae = mean_absolute_error(y_test_gdf, VALFIN)\n",
        "print(f\"Testing Mean Absolute Error: {testing_mae}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "kFbgYJWlX7vq",
      "metadata": {
        "id": "kFbgYJWlX7vq"
      },
      "source": [
        "####MODE PREDICTIONS OF THE TREES\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "h1gWGQubYAaY",
      "metadata": {
        "id": "h1gWGQubYAaY"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from scipy.stats import mode\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "tree_predictions = np.array([tree.predict(X_test_gdf_scaled) for tree in RF_FINALBOSS4_scale.estimators_])\n",
        "rounded_predictions = np.round(tree_predictions, 3)\n",
        "final_predictions = mode(rounded_predictions, axis=0)[0].flatten()\n",
        "print(\"Final Predictions (Mode of Rounded Predictions):\", final_predictions)\n",
        "r2 = r2_score(y_test_gdf, final_predictions)\n",
        "print(\"R¬≤ Score:\", r2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "UcYaQtp4xpw1",
      "metadata": {
        "id": "UcYaQtp4xpw1"
      },
      "outputs": [],
      "source": [
        "\n",
        "tree_predictions = np.array([tree.predict(X_test_gdf_scaled) for tree in RF_FINALBOSS4_scale.estimators_])\n",
        "mean_predictions = np.mean(tree_predictions, axis=0)\n",
        "p5_predictions   = np.percentile(tree_predictions, 5, axis=0)\n",
        "p95_predictions  = np.percentile(tree_predictions, 95, axis=0)\n",
        "median_predictions = np.median(tree_predictions, axis=0)\n",
        "\n",
        "results_df = pd.DataFrame({\n",
        "    'Mean Predictions': mean_predictions,\n",
        "    '5th Percentile': p5_predictions,\n",
        "    '95th Percentile': p95_predictions,\n",
        "    'Median Predictions': median_predictions,\n",
        "    'Uncertainty (PI Width)': p95_predictions - p5_predictions\n",
        "})\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "WVJ3T8U717lo",
      "metadata": {
        "id": "WVJ3T8U717lo"
      },
      "outputs": [],
      "source": [
        "test_gdf = test_gdf.copy()\n",
        "test_gdf[\"mean_pred\"] = mean_predictions\n",
        "test_gdf[\"p5_pred\"] = p5_predictions\n",
        "test_gdf[\"p95_pred\"] = p95_predictions\n",
        "test_gdf[\"pi_width\"] = p95_predictions - p5_predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9f0smxw5_Xb",
      "metadata": {
        "id": "e9f0smxw5_Xb"
      },
      "outputs": [],
      "source": [
        "test_gdf.plot(column=\"mean_pred\", cmap=\"coolwarm\", legend=True)\n",
        "test_gdf.plot(column=\"pi_width\", cmap=\"viridis\", legend=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8RSxylRS_HKB",
      "metadata": {
        "id": "8RSxylRS_HKB"
      },
      "outputs": [],
      "source": [
        "# HOTSPOT : Moran‚Äôs I\n",
        "results = []\n",
        "min_cells = 10\n",
        "\n",
        "for s_id, subset in grid_gdf.groupby(\"settlement_id\"):\n",
        "    if len(subset) < min_cells:\n",
        "        print(f\"Skipping settlement {s_id} (too few cells: {len(subset)})\")\n",
        "        subset[\"Is\"] = np.nan\n",
        "        subset[\"q\"] = np.nan\n",
        "        subset[\"p_sim\"] = np.nan\n",
        "        results.append(subset)\n",
        "        continue\n",
        "\n",
        "    print(f\"Running Local Moran's I for settlement {s_id} ...\")\n",
        "    w = ps.weights.DistanceBand.from_dataframe(subset, threshold=threshold, silence_warnings=True)\n",
        "\n",
        "\n",
        "    y = subset[\"mean_pred\"].values\n",
        "    moran_loc = Moran_Local(y, w)\n",
        "    subset[\"Is\"] = moran_loc.Is\n",
        "    subset[\"q\"] = moran_loc.q\n",
        "    subset[\"p_sim\"] = moran_loc.p_sim\n",
        "\n",
        "    results.append(subset)\n",
        "grid_gdf_moran = gpd.GeoDataFrame(pd.concat(results), crs=grid_gdf.crs)\n",
        "def classify_hotcold(row):\n",
        "    if row[\"q\"] == 1:\n",
        "        if row[\"p_sim\"] < 0.01: return \"Hotspot (99%)\"\n",
        "        elif row[\"p_sim\"] < 0.05: return \"Hotspot (95%)\"\n",
        "        elif row[\"p_sim\"] < 0.10: return \"Hotspot (90%)\"\n",
        "    elif row[\"q\"] == 2:\n",
        "        if row[\"p_sim\"] < 0.01: return \"Coldspot (99%)\"\n",
        "        elif row[\"p_sim\"] < 0.05: return \"Coldspot (95%)\"\n",
        "        elif row[\"p_sim\"] < 0.10: return \"Coldspot (90%)\"\n",
        "    return \"Insignificant\"\n",
        "\n",
        "grid_gdf_moran[\"hotcold_label\"] = grid_gdf_moran.apply(classify_hotcold, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "RNpoQnJFCGii",
      "metadata": {
        "id": "RNpoQnJFCGii"
      },
      "outputs": [],
      "source": [
        "def classify_hotcold_numeric(row):\n",
        "    if row[\"q\"] == 1:  # High-High (Hotspot)\n",
        "        if row[\"p_sim\"] < 0.01: return 1   # Hotspot 99%\n",
        "        elif row[\"p_sim\"] < 0.05: return 2  # Hotspot 95%\n",
        "        elif row[\"p_sim\"] < 0.10: return 3  # Hotspot 90%\n",
        "    elif row[\"q\"] == 2:  # Low-Low (Coldspot)\n",
        "        if row[\"p_sim\"] < 0.01: return 4   # Coldspot 99%\n",
        "        elif row[\"p_sim\"] < 0.05: return 5  # Coldspot 95%\n",
        "        elif row[\"p_sim\"] < 0.10: return 6  # Coldspot 90%\n",
        "    return 7  # Insignificant\n",
        "\n",
        "grid_gdf_moran[\"hotcold_code\"] = grid_gdf_moran.apply(classify_hotcold_numeric, axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "IaT1uDkOLiaL",
      "metadata": {
        "collapsed": true,
        "id": "IaT1uDkOLiaL"
      },
      "outputs": [],
      "source": [
        "importances = RF1.feature_importances_\n",
        "for i, feature_name in enumerate(X_test_gdf.columns):\n",
        "    print(f\"{feature_name}: {importances[i]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "IYEknVZfMJDs",
      "metadata": {
        "collapsed": true,
        "id": "IYEknVZfMJDs"
      },
      "outputs": [],
      "source": [
        "feature_importances_df = pd.DataFrame({\n",
        "   'Feature': X_test_gdf.columns,\n",
        "    'Importance': importances\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "n2JUNR3iQtg4",
      "metadata": {
        "id": "n2JUNR3iQtg4"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "data = feature_importances_df.head(8).copy()\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "norm = plt.Normalize(data['Importance'].min(), data['Importance'].max())\n",
        "colors = plt.cm.Greens(norm(data['Importance']))\n",
        "\n",
        "bars = plt.barh(data['Feature'], data['Importance'],\n",
        "                color=colors, edgecolor='black')\n",
        "for bar in bars:\n",
        "    plt.text(bar.get_width(),\n",
        "             bar.get_y() + bar.get_height()/2,\n",
        "             f'{bar.get_width():.3f}',\n",
        "             va='center', fontsize=12, color='black')\n",
        "\n",
        "plt.xlabel('Importance', fontsize=20, fontweight='bold')\n",
        "plt.ylabel('Feature', fontsize=20, fontweight='bold')\n",
        "plt.xticks(fontsize=15, fontweight='bold')\n",
        "plt.yticks(fontsize=15, fontweight='bold')\n",
        "plt.title('Gini Feature Importance: Nairobi', fontsize=24, fontweight='bold', loc='center')\n",
        "\n",
        "plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
        "plt.gca().invert_yaxis()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1hnc6xz58rZc",
      "metadata": {
        "id": "1hnc6xz58rZc"
      },
      "outputs": [],
      "source": [
        "from sklearn.inspection import permutation_importance\n",
        "results = permutation_importance(RF1, X_test_gdf_scaled, y_test_gdf, n_repeats=30, random_state=42)\n",
        "\n",
        "feature_importances_df = pd.DataFrame({\n",
        "    'Feature': X_test_gdf.columns,\n",
        "    'Importance': results.importances_mean\n",
        "})\n",
        "\n",
        "feature_importances_df = feature_importances_df.sort_values('Importance', ascending=False)\n",
        "feature_importances_df20 = feature_importances_df.head(20)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "28994264-c1d3-407f-aba0-005eb320ea22",
      "metadata": {
        "id": "28994264-c1d3-407f-aba0-005eb320ea22"
      },
      "source": [
        "##PREDICTION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6K32Cv75fCWF",
      "metadata": {
        "id": "6K32Cv75fCWF"
      },
      "outputs": [],
      "source": [
        "FINAL_PRED = '/content/drive/My Drive/PHD/Onekana/Modelling/Objective 3(Modelling)/Input/Predict_Grids.gpkg'\n",
        "PRED_AOI = gpd.read_file(FINAL_PRED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ARF-3tl-NYtv",
      "metadata": {
        "collapsed": true,
        "id": "ARF-3tl-NYtv"
      },
      "outputs": [],
      "source": [
        "final_gdf = PRED_AOI\n",
        "concatenated_gdf_GEOM= final_gdf['geometry'].to_frame()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9fa7a90e-c20f-4069-9a49-c3206c8a4812",
      "metadata": {
        "id": "9fa7a90e-c20f-4069-9a49-c3206c8a4812"
      },
      "outputs": [],
      "source": [
        "final_gdf = final_gdf.drop(columns=['geometry'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "TFpwIFJpma39",
      "metadata": {
        "id": "TFpwIFJpma39"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open(file_path, 'rb') as file:\n",
        "    RF1 = pickle.load(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b696cb5-2672-4070-a667-d655a7731bfc",
      "metadata": {
        "id": "8b696cb5-2672-4070-a667-d655a7731bfc"
      },
      "outputs": [],
      "source": [
        "predictions = RF1.predict(final_gdf)\n",
        "\n",
        "sns.set(style=\"whitegrid\")\n",
        "sns.kdeplot(predictions, fill=True, color=\"darkblue\");\n",
        "\n",
        "plt.title('PDF of Predicted Values')\n",
        "plt.xlabel('Predicted Value')\n",
        "plt.ylabel('Density')\n",
        "plt.savefig('PDF Model1.png' , format ='png', dpi=300)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "mpINGtBaf2Wi",
      "metadata": {
        "id": "mpINGtBaf2Wi"
      },
      "outputs": [],
      "source": [
        "final_gdf['geometry'] = concatenated_gdf_GEOM\n",
        "final_gdf['predicted_value'] = predictions"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "h9wgDGm5X-Nx",
        "721c30d3-2140-4c96-a5e8-2f49754b706d",
        "0e3a1f3b-d1a2-4898-b119-b95e043cedfc",
        "5KoQkzUPYZlW",
        "AMqH1JRqYg0V"
      ],
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}